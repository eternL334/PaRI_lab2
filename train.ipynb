{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd00f16-6060-4be0-8e74-3bde35404283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T10:33:56.596567Z",
     "start_time": "2023-03-18T10:33:56.591114Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import numpy.testing as npt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import vgg13, VGG13_Weights\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import matplotlib_inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('pdf', 'svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571cb8d2-bbfb-4265-a35f-7f135a01bf48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T10:20:41.258866Z",
     "start_time": "2023-03-18T10:20:41.254084Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "class PhotosDataset(Dataset):\n",
    "    def __init__(self, images_dir, transforms=None):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        images_dir : str\n",
    "            Path to directory with images\n",
    "            \n",
    "        target_dir : str\n",
    "            Path to directory with masks.\n",
    "            Each mask corresponds to one image.\n",
    "            Corresponding mask and image have the same name, but different format.\n",
    "            \n",
    "        transforms : some collection\n",
    "            Sequence of transformations for images and masks. \n",
    "        \"\"\"\n",
    "        self.images_dir = images_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.names = [os.path.splitext(e) for e in os.listdir(images_dir)]\n",
    "        self.names = [e[0] for e in self.names if e[1] == '.bmp']\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "                   \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        idx : int\n",
    "            Index of image and mask\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        (image, mask)\n",
    "        \"\"\"\n",
    "        name = self.names[idx]\n",
    "        image = cv.imread(os.path.join(self.images_dir, name + '.bmp'))\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        mask = cv.imread(os.path.join(self.images_dir, name + '.png'))\n",
    "        mask = (cv.cvtColor(mask, cv.COLOR_BGR2GRAY) / 255)[..., None]\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "\n",
    "        return image, mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d6208a-4d02-4d5f-b61d-62da708be3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "transform_train = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    # A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
    "    A.RandomCrop(width=512, height=512),\n",
    "    A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "transform_test = A.Compose([\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(transpose_mask=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a71cd18-6340-40c1-8c0b-a66106762a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PhotosDataset(\n",
    "    images_dir='img',\n",
    "    transforms=transform_train\n",
    ")\n",
    "test_dataset = PhotosDataset(\n",
    "    images_dir='img',\n",
    "    transforms=transform_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c09e4-858f-4604-bcc7-f1b299af3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_dataset, batch_size=2, num_workers=0, shuffle=True, drop_last=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=2, num_workers=0, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4011c-50aa-4a72-9947-e737971e7f86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-18T11:00:04.933474Z",
     "start_time": "2023-03-18T11:00:04.928047Z"
    }
   },
   "outputs": [],
   "source": [
    "class VGG13Encoder(torch.nn.Module):\n",
    "    def __init__(self, num_blocks, weights=VGG13_Weights.DEFAULT):\n",
    "        super().__init__()\n",
    "        self.num_blocks = num_blocks\n",
    "        \n",
    "        # Будем использовать предобученную VGG13 в качестве backbone\n",
    "        feature_extractor = vgg13(weights=weights).features\n",
    "        \n",
    "        # Каждый блок энкодера U-Net — это блок VGG13 без MaxPool2d\n",
    "        self.blocks = torch.nn.ModuleList()\n",
    "        for idx in range(self.num_blocks):\n",
    "            # Возьмите нужные слои из `feature_extractor` для очередного U-Net блока\n",
    "            # Объедините их с помощью `torch.nn.Sequential`\n",
    "            self.blocks.append(\n",
    "               feature_extractor[5 * idx:5 * idx + 4] \n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        activations = []\n",
    "        for idx, block in enumerate(self.blocks):\n",
    "            # Примените очередной блок U-Net\n",
    "            # your code here\n",
    "            x = block(x)\n",
    "\n",
    "            # Сохраните активации для передачи их в декодер\n",
    "            # your code here\n",
    "            activations.append(x)\n",
    "\n",
    "            # При необходимости примените max-pool\n",
    "            # Можно использовать `torch.functional.F.max_pool2d`\n",
    "            # your code here\n",
    "            x = torch.functional.F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "            \n",
    "        return activations\n",
    "\n",
    "class DecoderBlock(torch.nn.Module):\n",
    "    def __init__(self, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upconv = torch.nn.Conv2d(\n",
    "            in_channels=out_channels * 2, out_channels=out_channels,\n",
    "            kernel_size=3, padding=1, dilation=1\n",
    "        )\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=out_channels, out_channels=out_channels,\n",
    "            kernel_size=3, padding=1, dilation=1\n",
    "        )\n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=out_channels, out_channels=out_channels,\n",
    "            kernel_size=3, padding=1, dilation=1\n",
    "        )\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, down, left):\n",
    "        # Upsample x2 и свёртка\n",
    "        # your code here\n",
    "        x = self.upconv(torch.nn.functional.interpolate(down, scale_factor=2))\n",
    "        \n",
    "        # Конкатенация выхода энкодера и предыдущего блока декодера\n",
    "        # your code here\n",
    "        x = x + left\n",
    "        \n",
    "        # Две свёртки с ReLu\n",
    "        # your code here\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, num_filters, num_blocks):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = torch.nn.ModuleList()\n",
    "        for idx in range(num_blocks):\n",
    "            self.blocks.insert(0, DecoderBlock(num_filters * 2 ** idx))   \n",
    "\n",
    "    def forward(self, acts):\n",
    "        up = acts[-1]\n",
    "        for block, left in zip(self.blocks, acts[-2::-1]):\n",
    "            up = block(up, left)\n",
    "        return up\n",
    "\n",
    "class LinkNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes=1, num_blocks=4):\n",
    "        super().__init__()\n",
    "        # your code here\n",
    "        self.encoder = VGG13Encoder(num_blocks)\n",
    "        \n",
    "        # your code here\n",
    "        self.decoder = Decoder(64, num_blocks - 1)\n",
    "        \n",
    "        # Свёртка 1x1 для попиксельной агрегации каналов\n",
    "        # your code here\n",
    "        self.final = torch.nn.Conv2d(64, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # your code here\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3725cca-0a6b-4cab-a6a2-a4321397062e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T14:00:09.223608Z",
     "start_time": "2023-03-17T14:00:09.218409Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class IoUScore(torch.nn.Module):\n",
    "    def __init__(self, threshold, reduction=None):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        threshold : float\n",
    "            threshold for logits binarization\n",
    "        reduction : Optional[str] (None, 'mean' or 'sum')\n",
    "            specifies the reduction to apply to the output:\n",
    "            \n",
    "            None: no reduction will be applied\n",
    "            'mean': the sum of the output will be divided by the number of elements in the batch\n",
    "            'sum':  the output will be summed. \n",
    "        with_logits : bool\n",
    "            If True, use additional sigmoid for inputs\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.threshold = threshold\n",
    "        self.reduction = reduction\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def forward(self, logits, true_labels):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: torch.Tensor\n",
    "            Unnormalized probability of true class. Shape: [B, ...]\n",
    "        true_labels: torch.Tensor\n",
    "            Mask of correct predictions. Shape: [B, ...]\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            If reduction is 'mean' or 'sum' returns a tensor with a single element\n",
    "            Otherwise, returns a tensor of shape [B]\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        dims = list(range(1, logits.ndim))\n",
    "        logits = logits > self.threshold\n",
    "\n",
    "        score = torch.sum(logits * true_labels, dim=dims) / torch.sum(logits + true_labels - logits * true_labels, dim=dims)\n",
    "        \n",
    "        if self.reduction == 'sum':\n",
    "            # your code here\n",
    "            score = torch.sum(score)\n",
    "        elif self.reduction == 'mean':\n",
    "            # your code here\n",
    "            score = torch.mean(score)\n",
    "            \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50cd25-2242-4bb7-80b8-4502aa543599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-17T14:00:39.274913Z",
     "start_time": "2023-03-17T14:00:39.269110Z"
    }
   },
   "outputs": [],
   "source": [
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, eps=1e-7, reduction=None, with_logits=True):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        eps : float\n",
    "            eps in denominator\n",
    "        reduction : Optional[str] (None, 'mean' or 'sum')\n",
    "            specifies the reduction to apply to the output:\n",
    "            \n",
    "            None: no reduction will be applied\n",
    "            'mean': the sum of the output will be divided by the number of elements in the batch\n",
    "            'sum':  the output will be summed. \n",
    "        with_logits : bool\n",
    "            If True, use additional sigmoid for inputs\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "        self.with_logits = with_logits\n",
    "        \n",
    "    def forward(self, logits, true_labels):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: torch.Tensor\n",
    "            Unnormalized probability of true class. Shape: [B, ...]\n",
    "        true_labels: torch.Tensor\n",
    "            Mask of correct predictions. Shape: [B, ...]\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            If reduction is 'mean' or 'sum' returns a tensor with a single element\n",
    "            Otherwise, returns a tensor of shape [B]\n",
    "        \"\"\"\n",
    "        true_labels = true_labels.to(torch.long)\n",
    "        \n",
    "        if self.with_logits:\n",
    "            logits = torch.sigmoid(logits)\n",
    "\n",
    "        dims = list(range(1, logits.ndim))\n",
    "\n",
    "        loss_value = 1 - 2 * torch.sum(logits * true_labels, dim=dims) / torch.sum(logits + true_labels + self.eps, dim=dims)\n",
    "        \n",
    "        if self.reduction == 'sum':\n",
    "            loss_value = torch.sum(loss_value)\n",
    "        elif self.reduction == 'mean':\n",
    "            # your code here\n",
    "            loss_value = torch.mean(loss_value)\n",
    "        elif self.reduction is None:\n",
    "            pass\n",
    "        return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bcc77f-b1c7-446a-b408-444c5676c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(image, mask, logits):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(12, 6))\n",
    "    \n",
    "    image = image.permute(1, 2, 0).numpy()\n",
    "    image = (image * np.array([0.229, 0.224, 0.225])) + np.array([0.485, 0.456, 0.406])\n",
    "    image = np.clip(image, 0, 1)\n",
    "\n",
    "    mask = mask.squeeze(0).numpy()\n",
    "    logits = logits.squeeze(0).numpy()\n",
    "    logits_binarized = logits > 0.0\n",
    "\n",
    "    axs[0].imshow(image)\n",
    "    axs[1].imshow(mask, cmap='gray')\n",
    "    axs[2].imshow(logits, cmap='gray')\n",
    "    axs[3].imshow(logits_binarized, cmap='gray')\n",
    "\n",
    "    axs[0].axis('off')\n",
    "    axs[1].axis('off')\n",
    "    axs[2].axis('off')\n",
    "    axs[3].axis('off')\n",
    "\n",
    "    axs[0].set_title('Original')\n",
    "    axs[1].set_title('True mask')\n",
    "    axs[2].set_title('Pred mask')\n",
    "    axs[3].set_title('Binarized mask')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecedb01-65b3-4f62-9e06-71687784273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class Runner:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        n_epochs,\n",
    "        loss,\n",
    "        optimizer,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        writer,\n",
    "        metrics=None,\n",
    "        logging_interval=1.0,\n",
    "        scheduler=None,\n",
    "        model_name='model',\n",
    "        log_images=None,\n",
    "        image_log_interval=10\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.n_epochs = n_epochs\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.metrics = metrics\n",
    "        self.writer = writer\n",
    "        self.logging_interval = logging_interval\n",
    "        self.scheduler = scheduler\n",
    "        self.model_name = model_name\n",
    "        self.log_images = log_images\n",
    "        \n",
    "        self.global_step = 0\n",
    "        self.activations = []\n",
    "\n",
    "        if self.metrics is None:\n",
    "            self.metrics = dict()\n",
    "\n",
    "        self.image_log_interval = image_log_interval\n",
    "        self.image_log_idx = 0\n",
    "        \n",
    "    \n",
    "    def train(self):\n",
    "        logging_batch = int(self.logging_interval * len(self.train_loader))\n",
    "    \n",
    "        running_loss = 0\n",
    "        running_metrics = {metric_name: 0 for metric_name in self.metrics}\n",
    "    \n",
    "        self.model.train()  # switch network submodules to train mode, e.g. it influences on batch-norm, dropout\n",
    "        for i, (images, labels) in enumerate(self.train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)   # send data to device\n",
    "            self.optimizer.zero_grad()   # zero out grads, collected from previous batch\n",
    "            logits = self.model(images)  # forward pass\n",
    "            loss = self.loss(logits, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss\n",
    "\n",
    "            for metric_name in self.metrics:\n",
    "                running_metrics[metric_name] += self.metrics[metric_name](logits, labels)\n",
    "    \n",
    "            if i % logging_batch == logging_batch - 1:\n",
    "                self.global_step += 1\n",
    "                self.writer.add_scalar(\"Loss/train\", running_loss / logging_batch, global_step=self.global_step)\n",
    "                running_loss = 0\n",
    "                \n",
    "                for metric_name in self.metrics:\n",
    "                    self.writer.add_scalar(f\"{metric_name}/train\", running_metrics[metric_name] / logging_batch, global_step=self.global_step)\n",
    "                    running_metrics[metric_name] = 0\n",
    "    \n",
    "        \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def test(self):\n",
    "        \"\"\"calculate loss and accuracy on validation data\"\"\"\n",
    "        running_loss = 0\n",
    "        running_metrics = {metric_name: 0 for metric_name in self.metrics}\n",
    "\n",
    "        log_idx = 0\n",
    "        self.image_log_idx = (self.image_log_idx + 1) % self.image_log_interval\n",
    "        self.model.eval()  # switch network submodules to test mode\n",
    "        for images, labels in self.test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = self.model(images)\n",
    "            running_loss += self.loss(logits, labels)\n",
    "            for metric_name in self.metrics:\n",
    "                running_metrics[metric_name] += self.metrics[metric_name](logits, labels)\n",
    "\n",
    "            if self.image_log_idx == 0:\n",
    "                for image, label, logit in zip(images, labels, logits):\n",
    "                    fig = generate_plot(image.cpu(), label.cpu(), logit.detach().cpu())\n",
    "                    self.writer.add_figure(f\"Images/{log_idx}\", fig, global_step=self.global_step)\n",
    "                    log_idx += 1\n",
    "\n",
    "        l = len(self.test_loader)\n",
    "    \n",
    "        self.writer.add_scalar(\"Loss/test\", running_loss / l, global_step=self.global_step)\n",
    "        for metric_name in self.metrics:\n",
    "            self.writer.add_scalar(f\"{metric_name}/test\", running_metrics[metric_name] / l, global_step=self.global_step)\n",
    "\n",
    "        return running_loss, running_metrics\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"full cycle of neural network training\"\"\"\n",
    "\n",
    "        min_loss, min_metrics = self.test()\n",
    "            \n",
    "        for epoch in tqdm(range(self.n_epochs)):\n",
    "            self.train()\n",
    "            loss, metrics = self.test()\n",
    "    \n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step(loss)\n",
    "                lr = self.scheduler.get_last_lr()[0]\n",
    "                self.writer.add_scalar(\"Learning rate\", lr, global_step=self.global_step)\n",
    "    \n",
    "            if loss < min_loss:\n",
    "                min_loss = loss\n",
    "                min_metrics = metrics\n",
    "                torch.save(self.model.state_dict(), f\"{self.model_name}_model.pt\")\n",
    "                torch.save(self.optimizer.state_dict(), f\"{self.model_name}_optim.pt\")\n",
    "                \n",
    "    \n",
    "        return min_loss, min_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd807bbd-249c-4d04-a713-e72a97bbc09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [04:37<00:00,  2.78s/it]\n"
     ]
    }
   ],
   "source": [
    "model = LinkNet(num_classes=1, num_blocks=3)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "writer = SummaryWriter('runs/LinkNet')\n",
    "\n",
    "metrics = {'Dice loss': DiceLoss(reduction='mean'), 'IoU': IoUScore(threshold=0.0, reduction='mean')}\n",
    "\n",
    "runner = Runner(\n",
    "    model,\n",
    "    100,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    train_data_loader,\n",
    "    test_data_loader,\n",
    "    writer,\n",
    "    logging_interval=1.0,\n",
    "    scheduler=scheduler,\n",
    "    metrics=metrics,\n",
    "    model_name=\"LinkNet\",\n",
    ") \n",
    "\n",
    "loss_res, metrics_res = runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f22633e-521f-4a31-812e-d177d8b5186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"LinkNet_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
